{
    "item_type": "proposal",
    "title": "Data-centric Parallel Programming",
    "descriptions": [
        {
            "proposal_name": "Data-centric Parallel Programming",
            "proposal_details": {
                "challenge_addressed": "programming large-scale heterogeneous parallel computers",
                "applications": [
                    "drug design",
                    "weather prediction",
                    "big data analytics"
                ],
                "architectural_trends": [
                    "heterogeneous parallel processors",
                    "quad-core laptops",
                    "million-core supercomputers"
                ],
                "importance": [
                    "efficient exploitation of architectures",
                    "technological advancement"
                ],
                "problem_nature": "computationally demanding problems are inherently parallel",
                "compilation_target": "various architectures",
                "difficulty": "efficiently mapping data to the target memory system",
                "data_access_cost": "growing with the amount of parallelism",
                "optimization_importance": "data layout",
                "current_paradigm": "control-centric model",
                "proposed_solution": {
                    "approach": "data-centric program formulation",
                    "program_representation": "collections of values called memlets",
                    "system_role": "mapped as first-class objects by the compiler and runtime system"
                },
                "system_goals": [
                    "advance the state of the art in parallel computing",
                    "combine static and dynamic scheduling of memlets",
                    "handle complex heterogeneous target architectures"
                ],
                "demonstration_applications": [
                    "scientific computing",
                    "data analytics",
                    "graph processing"
                ],
                "conclusion": "holistic data-centric programming is essential to avoid scaling wall in computational capabilities"
            }
        },
        {
            "proposal_name": "Data-centric Parallel Programming",
            "proposal_details": {
                "challenge": "programming large-scale heterogeneous parallel computers",
                "importance": [
                    "drug design",
                    "weather prediction",
                    "big data analytics"
                ],
                "architectural_trends": "heterogeneous parallel processors",
                "computing_platforms": [
                    "quad-core laptops",
                    "million-core supercomputers"
                ],
                "parallel_problems": "inherently parallel",
                "data_mapping_difficulty": "notoriously hard",
                "data_access_cost": "growing with the amount of parallelism",
                "data_layout_optimizations": "crucial",
                "current_paradigm": "control-centric model",
                "proposed_solution": "data-centric program formulation",
                "program_representation": "collections of values (memlets)",
                "compiler_runtime_system": "holistic",
                "scheduling": [
                    "static",
                    "dynamic"
                ],
                "target_architectures": "complex heterogeneous",
                "applications_demonstrated": [
                    "scientific computing",
                    "data analytics",
                    "graph processing"
                ],
                "consequence_without_solution": "scaling wall limiting computational capabilities",
                "descriptions": [
                    "Our holistic compiler and runtime system aims to substantially advance the state of the art in parallel computing by combining static and dynamic scheduling of memlets to complex heterogeneous target architectures."
                ]
            }
        },
        {
            "proposal_name": "Data-centric Parallel Programming",
            "proposal_details": {
                "challenge": "programming large-scale heterogeneous parallel computers",
                "applications": [
                    "drug design",
                    "weather prediction",
                    "big data analytics"
                ],
                "computing_platforms_range": [
                    "quad-core laptops",
                    "million-core supercomputers"
                ],
                "problem": "mapping data to target memory system",
                "data_access_cost": "growing with amount of parallelism",
                "current_abstractions": "ignore data access",
                "approach": "data-centric program formulation",
                "memlets": "collections of values mapped by compiler and runtime system",
                "system_features": [
                    "static and dynamic scheduling",
                    "complex heterogeneous target architectures"
                ],
                "applications_demonstrated": [
                    "scientific computing",
                    "data analytics",
                    "graph processing"
                ],
                "descriptions": [
                    "Holistic data-centric programming is crucial to prevent a scaling wall in future computational capabilities."
                ]
            }
        }
    ],
    "origin": "LLM",
    "llm_engine": "gpt-4-1106-preview",
    "generation_prompt_uid": "826e52d7628d189a10d3faab6d4a0fd3",
    "generation_prompt_nickname": "jsonify_key_details_proposal",
    "generation_prompt_text": "Extract and present the key details from this grant proposal abstract in valid JSON format. Keep array structures simple and flat where possible. Focus only on capturing the concrete features, characteristics, and data points - exclude any narrative text or prose descriptions. The response should contain exactly one item in the 'descriptions' array!\n\n---\n\n**Title:**\n\nData-centric Parallel Programming\n\n**Description:**\n\nWe address a fundamental and increasingly important challenge in computer science: how to program large-scale heterogeneous parallel computers. Society relies on these computers to satisfy the growing demands of important applications such as drug design, weather prediction, and big data analytics. Architectural trends make heterogeneous parallel processors the fundamental building blocks of computing platforms ranging from quad-core laptops to million-core supercomputers; failing to exploit these architectures efficiently will severely limit the technological advance of our society. Computationally demanding problems are often inherently parallel and can readily be compiled for various target architectures. Yet, efficiently mapping data to the target memory system is notoriously hard, and the cost of fetching two operands from remote memory is already orders of magnitude more expensive than any arithmetic operation. Data access cost is growing with the amount of parallelism which makes data layout optimizations crucial. Prevalent parallel programming abstractions largely ignore data access and guide programmers to design threads of execution that are scheduled to the machine. We depart from this control-centric model to a data-centric program formulation where we express programs as collections of values, called memlets, that are mapped as first-class objects by the compiler and runtime system. Our holistic compiler and runtime system aims to substantially advance the state of the art in parallel computing by combining static and dynamic scheduling of memlets to complex heterogeneous target architectures. We will demonstrate our methods on three challenging real-world applications in scientific computing, data analytics, and graph processing. We strongly believe that, without holistic data-centric programming, the growing complexity and inefficiency of parallel programming will create a scaling wall that will limit our future computational capabilities."
}