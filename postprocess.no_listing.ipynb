{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b46fa0f-c4f5-48cc-af91-570c07b0ee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9bb60e9-abf7-4d60-ac3b-e3cc541dcbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = f.read()\n",
    "    return json.loads(data)[\"results\"]\n",
    "\n",
    "\n",
    "def short_name(name):\n",
    "    if name == \"gpt-3.5-turbo-1106\":\n",
    "        return \"gpt-3.5-turbo\"\n",
    "    if \"/\" in name:\n",
    "        name = name.split(\"/\")[1]\n",
    "    for k in [\"-Instruct\", \"-preview\"]:\n",
    "        if k in name:\n",
    "            name = name.split(k)[0]\n",
    "    return name.lower()\n",
    "\n",
    "def describe_df(df: pd.DataFrame, name=\"\", print_max=10):\n",
    "    print(f\"Dataframe {name} with {df.shape[0]} rows and {df.shape[1]} columns:\")\n",
    "    maxlen = max(len(c) for c in df.columns) + 2\n",
    "    for c in df.columns:\n",
    "        a = np.array(df[c].unique())\n",
    "        a.sort()\n",
    "        if len(a) < print_max:\n",
    "            print(f\"{(c+':').ljust(maxlen)} {a}\")\n",
    "        else:\n",
    "            print(f\"{(c+':').ljust(maxlen)} {a[:10]}[...] ({len(a)} unique values)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2555c5-e781-42f3-9eed-37cee6f48b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c8efd81-0d10-4641-bebf-d4f0d4cf8756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF2:\n",
      "size      is the number of VALID responses\n",
      "llm_count is the number of preferences for LLM-generated responses\n",
      "value     is the fraction preference for LLM-generated alternatives, out of VALID\n",
      "ci0, ci1  is the WIDTH of the 95% confidence interval LEFT and RIGHT of `value`\n",
      "p_value   is the p-value for the null hypothesis that the discriminator is indifferent (p0=0.5, either side)\n",
      "\n",
      "Dataframe df2 with 81 rows and 13 columns:\n",
      "desc_model:    ['gpt-3.5-turbo' 'gpt-4-1106' 'meta-llama-3.1-70b' 'mixtral-8x22b' 'qwen2.5-72b']\n",
      "cmp_model:     ['gpt-3.5-turbo' 'gpt-4-1106' 'humans' 'meta-llama-3.1-70b' 'mixtral-8x22b' 'qwen2.5-72b']\n",
      "name:          ['movie' 'paper' 'product']\n",
      "ftype:         ['from_json_details' 'from_title_and_year' 'write_xml_paper_abstract_control_word_count']\n",
      "value:         [0.28 0.29 0.31 0.36 0.42 0.46 0.47 0.48 0.48 0.49][...] (78 unique values)\n",
      "size:          [ 75 143 152 154 163 166 167 170 172 174][...] (41 unique values)\n",
      "llm_count:     [ 23  36  62  69  78  81  86  93 101 103][...] (66 unique values)\n",
      "original_key:  ['movie---DESCRIPTION-from_title_and_year|gpt-3.5-turbo---COMPARISON-movie_pick_one|gpt-3.5-turbo'\n",
      " 'movie---DESCRIPTION-from_title_and_year|gpt-3.5-turbo---COMPARISON-movie_pick_one|gpt-4-1106-preview'\n",
      " 'movie---DESCRIPTION-from_title_and_year|gpt-3.5-turbo---COMPARISON-movie_pick_one|together-Qwen/Qwen2.5-72B-Instruct-Turbo'\n",
      " 'movie---DESCRIPTION-from_title_and_year|gpt-3.5-turbo---COMPARISON-movie_pick_one|together-meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo'\n",
      " 'movie---DESCRIPTION-from_title_and_year|gpt-3.5-turbo---COMPARISON-movie_pick_one|together-mistralai/Mixtral-8x22B-Instruct-v0.1'\n",
      " 'movie---DESCRIPTION-from_title_and_year|gpt-4-1106-preview---COMPARISON-movie_pick_one|gpt-3.5-turbo'\n",
      " 'movie---DESCRIPTION-from_title_and_year|gpt-4-1106-preview---COMPARISON-movie_pick_one|gpt-4-1106-preview'\n",
      " 'movie---DESCRIPTION-from_title_and_year|gpt-4-1106-preview---COMPARISON-movie_pick_one|together-Qwen/Qwen2.5-72B-Instruct-Turbo'\n",
      " 'movie---DESCRIPTION-from_title_and_year|gpt-4-1106-preview---COMPARISON-movie_pick_one|together-meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo'\n",
      " 'movie---DESCRIPTION-from_title_and_year|gpt-4-1106-preview---COMPARISON-movie_pick_one|together-mistralai/Mixtral-8x22B-Instruct-v0.1'][...] (81 unique values)\n",
      "ci0:           [0.02 0.03 0.03 0.04 0.04 0.04 0.04 0.04 0.04 0.04][...] (80 unique values)\n",
      "ci1:           [0.02 0.02 0.03 0.03 0.03 0.03 0.03 0.04 0.04 0.04][...] (80 unique values)\n",
      "p_value:       [4.98e-57 1.42e-48 3.52e-47 9.91e-43 1.06e-42 1.57e-38 1.43e-35 3.03e-35 9.78e-35 5.83e-33][...] (79 unique values)\n",
      "offset:        [-0.25 -0.17 -0.08  0.    0.08  0.17]\n",
      "title:         ['movie' 'paper' 'product/details']\n",
      "\n",
      "Dataframe df with 243 rows and 6 columns:\n",
      "name:        ['movie' 'paper' 'product']\n",
      "ftype:       ['from_json_details' 'from_title_and_year' 'write_xml_paper_abstract_control_word_count']\n",
      "desc_model:  ['gpt-3.5-turbo' 'gpt-4-1106' 'meta-llama-3.1-70b' 'mixtral-8x22b' 'qwen2.5-72b']\n",
      "cmp_model:   ['gpt-3.5-turbo' 'gpt-4-1106' 'humans' 'meta-llama-3.1-70b' 'mixtral-8x22b' 'qwen2.5-72b']\n",
      "rtype:       ['human' 'invalid' 'llm']\n",
      "rvalue:      [ 0  1  2  3  4  5  9 10 11 12][...] (139 unique values)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_and_process_files(file_paths):\n",
    "    all_results = {}\n",
    "    data = []\n",
    "    data2 = []\n",
    "    seen_keys = {}  # Track original keys and their source files\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path) as f:\n",
    "            results = json.loads(f.read())\n",
    "\n",
    "        # Check for duplicate keys across files\n",
    "        overlap = set(results.keys()) & set(all_results.keys())\n",
    "        if overlap:\n",
    "            raise ValueError(f\"Duplicate keys found across files: {overlap}\")\n",
    "\n",
    "        all_results.update(results)\n",
    "\n",
    "    for key, value in all_results.items():\n",
    "        x = key.split(\"|\")\n",
    "        name, fromtype = x[0].split(\"---DESCRIPTION-\")\n",
    "        desc_model = x[1].split(\"---COMPARISON\")[0]\n",
    "        cmp_model = x[2]\n",
    "        values = value[\"total_tallies\"]\n",
    "        desc_model = short_name(desc_model)\n",
    "        desc_model = desc_model.replace(\"gpt3_5\", \"gpt-3.5-turbo\").replace(\"gpt4\", \"gpt-4-1106\")\n",
    "        cmp_model = short_name(cmp_model)\n",
    "\n",
    "        if cmp_model.startswith(\"Qwen1.5\"):\n",
    "            continue\n",
    "\n",
    "        row = (name, fromtype, desc_model, cmp_model)\n",
    "        data.append(row + (\"human\", values[\"Human\"]))\n",
    "        data.append(row + (\"llm\", values[\"LLM\"]))\n",
    "        data.append(row + (\"invalid\", values[\"Invalid\"]))\n",
    "\n",
    "        total = values[\"Human\"] + values[\"LLM\"]\n",
    "        if total > 0:\n",
    "            identifier = (desc_model, cmp_model, name, fromtype)\n",
    "            if identifier in seen_keys:\n",
    "                raise ValueError(\n",
    "                    f\"Duplicate combination found: {identifier}\\n\"\n",
    "                    f\"Key 1: {seen_keys[identifier]}\\n\"\n",
    "                    f\"Key 2: {key}\"\n",
    "                )\n",
    "            seen_keys[identifier] = key\n",
    "            data2.append(\n",
    "                (\n",
    "                    desc_model,\n",
    "                    cmp_model,\n",
    "                    name,\n",
    "                    fromtype,\n",
    "                    float(values[\"LLM\"]) / total,\n",
    "                    total,\n",
    "                    values[\"LLM\"],\n",
    "                    key,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        data, columns=[\"name\", \"ftype\", \"desc_model\", \"cmp_model\", \"rtype\", \"rvalue\"]\n",
    "    )\n",
    "    df2 = pd.DataFrame(\n",
    "        data2,\n",
    "        columns=[\n",
    "            \"desc_model\",\n",
    "            \"cmp_model\",\n",
    "            \"name\",\n",
    "            \"ftype\",\n",
    "            \"value\",\n",
    "            \"size\",\n",
    "            \"llm_count\",\n",
    "            \"original_key\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return df, df2\n",
    "\n",
    "\n",
    "MERGED_FILES = [\"merged_run_outputs/merged_llms.json\", \"merged_run_outputs/merged_humans_product-only_totals.json\", \"merged_run_outputs/merged_humans_movies.json\"]\n",
    "df, df2 = load_and_process_files(MERGED_FILES)\n",
    "\n",
    "# delete everything that contains ftype prorgram_listing\n",
    "df = df[~df.ftype.str.contains(\"listing\")]\n",
    "df2 = df2[~df2.ftype.str.contains(\"listing\")]\n",
    "\n",
    "### Now there are some duplicities, we need to combine them: sum size and llm_count, recompute value as llm_count / size\n",
    "# df2 = df2.groupby([\"desc_model\", \"cmp_model\", \"name\", \"ftype\"]).agg({\"size\": \"sum\", \"llm_count\": \"sum\", \"value\": \"first\"}).reset_index()\n",
    "# df2[\"value\"] = df2[\"llm_count\"] / df2[\"size\"]\n",
    "\n",
    "\n",
    "def compute_ci_and_p_level(row, null_hypothesis=0.5):\n",
    "    alpha = row[\"llm_count\"]\n",
    "    beta = row[\"size\"] - row[\"llm_count\"]\n",
    "    a, b = scipy.stats.beta.interval(0.95, alpha, beta)\n",
    "    p_value = scipy.stats.binomtest(\n",
    "        row[\"llm_count\"], row[\"size\"], p=null_hypothesis, alternative=\"two-sided\"\n",
    "    ).pvalue\n",
    "    return row[\"value\"] - a, b - row[\"value\"], p_value\n",
    "\n",
    "\n",
    "df2[[\"ci0\", \"ci1\", \"p_value\"]] = df2.apply(\n",
    "    lambda x: compute_ci_and_p_level(x), axis=1, result_type=\"expand\"\n",
    ")\n",
    "\n",
    "OFFSET_NAMES = sorted(df2.cmp_model.unique())\n",
    "\n",
    "df2[\"offset\"] = df2.cmp_model.apply(\n",
    "    lambda x: (OFFSET_NAMES.index(x) - len(OFFSET_NAMES) / 2) / (len(OFFSET_NAMES) * 2)\n",
    ")\n",
    "\n",
    "\n",
    "def make_title(x):\n",
    "    if x[\"name\"] == \"product\":\n",
    "        if x[\"ftype\"] == \"from_json_details\":\n",
    "            return \"product/details\"\n",
    "        elif x[\"ftype\"] == \"from_json_product_listing\":\n",
    "            return \"product/listing\"\n",
    "        else:\n",
    "            return \"product/???\"\n",
    "    else:\n",
    "        return x[\"name\"]\n",
    "\n",
    "\n",
    "df2[\"title\"] = df2.apply(make_title, axis=1)\n",
    "\n",
    "with np.printoptions(linewidth=120, precision=2):\n",
    "    print(\"DF2:\")\n",
    "    print(\"size      is the number of VALID responses\")\n",
    "    print(\"llm_count is the number of preferences for LLM-generated responses\")\n",
    "    print(\n",
    "        \"value     is the fraction preference for LLM-generated alternatives, out of VALID\"\n",
    "    )\n",
    "    print(\n",
    "        \"ci0, ci1  is the WIDTH of the 95% confidence interval LEFT and RIGHT of `value`\"\n",
    "    )\n",
    "    print(\n",
    "        \"p_value   is the p-value for the null hypothesis that the discriminator is indifferent (p0=0.5, either side)\"\n",
    "    )\n",
    "    print()\n",
    "    describe_df(df2, \"df2\")\n",
    "    print()\n",
    "    describe_df(df, \"df\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e14daf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pivot table showing value and p-value for task counts:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>desc_model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">gpt-3.5-turbo</th>\n",
       "      <th colspan=\"3\" halign=\"left\">gpt-4-1106</th>\n",
       "      <th colspan=\"3\" halign=\"left\">meta-llama-3.1-70b</th>\n",
       "      <th colspan=\"3\" halign=\"left\">mixtral-8x22b</th>\n",
       "      <th colspan=\"3\" halign=\"left\">qwen2.5-72b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th>mov</th>\n",
       "      <th>p-d</th>\n",
       "      <th>pap</th>\n",
       "      <th>mov</th>\n",
       "      <th>p-d</th>\n",
       "      <th>pap</th>\n",
       "      <th>mov</th>\n",
       "      <th>p-d</th>\n",
       "      <th>pap</th>\n",
       "      <th>mov</th>\n",
       "      <th>p-d</th>\n",
       "      <th>pap</th>\n",
       "      <th>mov</th>\n",
       "      <th>p-d</th>\n",
       "      <th>pap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>humans</th>\n",
       "      <td>0.480 (0.818)</td>\n",
       "      <td>0.280 (0.000)</td>\n",
       "      <td>0.462 (0.254)</td>\n",
       "      <td>0.307 (0.001)</td>\n",
       "      <td>0.290 (0.000)</td>\n",
       "      <td>0.601 (0.000)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>0.665 (0.000)</td>\n",
       "      <td>0.714 (0.000)</td>\n",
       "      <td>0.483 (0.738)</td>\n",
       "      <td>0.701 (0.000)</td>\n",
       "      <td>0.928 (0.000)</td>\n",
       "      <td>0.692 (0.000)</td>\n",
       "      <td>0.656 (0.000)</td>\n",
       "      <td>0.882 (0.000)</td>\n",
       "      <td>0.506 (0.936)</td>\n",
       "      <td>0.746 (0.000)</td>\n",
       "      <td>0.627 (0.000)</td>\n",
       "      <td>0.526 (0.573)</td>\n",
       "      <td>0.602 (0.000)</td>\n",
       "      <td>0.949 (0.000)</td>\n",
       "      <td>0.528 (0.531)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-1106</th>\n",
       "      <td>0.466 (0.140)</td>\n",
       "      <td>0.644 (0.000)</td>\n",
       "      <td>0.566 (0.123)</td>\n",
       "      <td>0.703 (0.000)</td>\n",
       "      <td>0.898 (0.000)</td>\n",
       "      <td>0.759 (0.000)</td>\n",
       "      <td>0.488 (0.622)</td>\n",
       "      <td>0.795 (0.000)</td>\n",
       "      <td>0.500 (1.000)</td>\n",
       "      <td>0.701 (0.000)</td>\n",
       "      <td>0.636 (0.000)</td>\n",
       "      <td>0.605 (0.008)</td>\n",
       "      <td>0.585 (0.000)</td>\n",
       "      <td>0.931 (0.000)</td>\n",
       "      <td>0.606 (0.007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama-3.1-70b</th>\n",
       "      <td>0.538 (0.098)</td>\n",
       "      <td>0.555 (0.121)</td>\n",
       "      <td>0.627 (0.001)</td>\n",
       "      <td>0.736 (0.000)</td>\n",
       "      <td>0.768 (0.000)</td>\n",
       "      <td>0.831 (0.000)</td>\n",
       "      <td>0.554 (0.018)</td>\n",
       "      <td>0.641 (0.000)</td>\n",
       "      <td>0.559 (0.123)</td>\n",
       "      <td>0.708 (0.000)</td>\n",
       "      <td>0.591 (0.008)</td>\n",
       "      <td>0.629 (0.001)</td>\n",
       "      <td>0.663 (0.000)</td>\n",
       "      <td>0.749 (0.000)</td>\n",
       "      <td>0.654 (0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixtral-8x22b</th>\n",
       "      <td>0.693 (0.000)</td>\n",
       "      <td>0.759 (0.000)</td>\n",
       "      <td>0.706 (0.000)</td>\n",
       "      <td>0.724 (0.000)</td>\n",
       "      <td>0.950 (0.000)</td>\n",
       "      <td>0.803 (0.000)</td>\n",
       "      <td>0.646 (0.000)</td>\n",
       "      <td>0.909 (0.000)</td>\n",
       "      <td>0.577 (0.045)</td>\n",
       "      <td>0.755 (0.000)</td>\n",
       "      <td>0.764 (0.000)</td>\n",
       "      <td>0.636 (0.000)</td>\n",
       "      <td>0.664 (0.000)</td>\n",
       "      <td>0.977 (0.000)</td>\n",
       "      <td>0.610 (0.004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen2.5-72b</th>\n",
       "      <td>0.359 (0.000)</td>\n",
       "      <td>0.627 (0.000)</td>\n",
       "      <td>0.488 (0.816)</td>\n",
       "      <td>0.612 (0.000)</td>\n",
       "      <td>0.891 (0.000)</td>\n",
       "      <td>0.777 (0.000)</td>\n",
       "      <td>0.420 (0.000)</td>\n",
       "      <td>0.727 (0.000)</td>\n",
       "      <td>0.500 (1.000)</td>\n",
       "      <td>0.695 (0.000)</td>\n",
       "      <td>0.600 (0.004)</td>\n",
       "      <td>0.565 (0.091)</td>\n",
       "      <td>0.694 (0.000)</td>\n",
       "      <td>0.927 (0.000)</td>\n",
       "      <td>0.589 (0.018)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "desc_model          gpt-3.5-turbo                                \\\n",
       "task                          mov            p-d            pap   \n",
       "cmp_model                                                         \n",
       "humans              0.480 (0.818)  0.280 (0.000)  0.462 (0.254)   \n",
       "gpt-3.5-turbo       0.665 (0.000)  0.714 (0.000)  0.483 (0.738)   \n",
       "gpt-4-1106          0.466 (0.140)  0.644 (0.000)  0.566 (0.123)   \n",
       "meta-llama-3.1-70b  0.538 (0.098)  0.555 (0.121)  0.627 (0.001)   \n",
       "mixtral-8x22b       0.693 (0.000)  0.759 (0.000)  0.706 (0.000)   \n",
       "qwen2.5-72b         0.359 (0.000)  0.627 (0.000)  0.488 (0.816)   \n",
       "\n",
       "desc_model             gpt-4-1106                                \\\n",
       "task                          mov            p-d            pap   \n",
       "cmp_model                                                         \n",
       "humans              0.307 (0.001)  0.290 (0.000)  0.601 (0.000)   \n",
       "gpt-3.5-turbo       0.701 (0.000)  0.928 (0.000)  0.692 (0.000)   \n",
       "gpt-4-1106          0.703 (0.000)  0.898 (0.000)  0.759 (0.000)   \n",
       "meta-llama-3.1-70b  0.736 (0.000)  0.768 (0.000)  0.831 (0.000)   \n",
       "mixtral-8x22b       0.724 (0.000)  0.950 (0.000)  0.803 (0.000)   \n",
       "qwen2.5-72b         0.612 (0.000)  0.891 (0.000)  0.777 (0.000)   \n",
       "\n",
       "desc_model         meta-llama-3.1-70b                                \\\n",
       "task                              mov            p-d            pap   \n",
       "cmp_model                                                             \n",
       "humans                                                                \n",
       "gpt-3.5-turbo           0.656 (0.000)  0.882 (0.000)  0.506 (0.936)   \n",
       "gpt-4-1106              0.488 (0.622)  0.795 (0.000)  0.500 (1.000)   \n",
       "meta-llama-3.1-70b      0.554 (0.018)  0.641 (0.000)  0.559 (0.123)   \n",
       "mixtral-8x22b           0.646 (0.000)  0.909 (0.000)  0.577 (0.045)   \n",
       "qwen2.5-72b             0.420 (0.000)  0.727 (0.000)  0.500 (1.000)   \n",
       "\n",
       "desc_model          mixtral-8x22b                                \\\n",
       "task                          mov            p-d            pap   \n",
       "cmp_model                                                         \n",
       "humans                                                            \n",
       "gpt-3.5-turbo       0.746 (0.000)  0.627 (0.000)  0.526 (0.573)   \n",
       "gpt-4-1106          0.701 (0.000)  0.636 (0.000)  0.605 (0.008)   \n",
       "meta-llama-3.1-70b  0.708 (0.000)  0.591 (0.008)  0.629 (0.001)   \n",
       "mixtral-8x22b       0.755 (0.000)  0.764 (0.000)  0.636 (0.000)   \n",
       "qwen2.5-72b         0.695 (0.000)  0.600 (0.004)  0.565 (0.091)   \n",
       "\n",
       "desc_model            qwen2.5-72b                                \n",
       "task                          mov            p-d            pap  \n",
       "cmp_model                                                        \n",
       "humans                                                           \n",
       "gpt-3.5-turbo       0.602 (0.000)  0.949 (0.000)  0.528 (0.531)  \n",
       "gpt-4-1106          0.585 (0.000)  0.931 (0.000)  0.606 (0.007)  \n",
       "meta-llama-3.1-70b  0.663 (0.000)  0.749 (0.000)  0.654 (0.000)  \n",
       "mixtral-8x22b       0.664 (0.000)  0.977 (0.000)  0.610 (0.004)  \n",
       "qwen2.5-72b         0.694 (0.000)  0.927 (0.000)  0.589 (0.018)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pivot table showing absolute counts (preference-for-llm of total valid):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>desc_model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">gpt-3.5-turbo</th>\n",
       "      <th colspan=\"3\" halign=\"left\">gpt-4-1106</th>\n",
       "      <th colspan=\"3\" halign=\"left\">meta-llama-3.1-70b</th>\n",
       "      <th colspan=\"3\" halign=\"left\">mixtral-8x22b</th>\n",
       "      <th colspan=\"3\" halign=\"left\">qwen2.5-72b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th>mov</th>\n",
       "      <th>p-d</th>\n",
       "      <th>pap</th>\n",
       "      <th>mov</th>\n",
       "      <th>p-d</th>\n",
       "      <th>pap</th>\n",
       "      <th>mov</th>\n",
       "      <th>p-d</th>\n",
       "      <th>pap</th>\n",
       "      <th>mov</th>\n",
       "      <th>p-d</th>\n",
       "      <th>pap</th>\n",
       "      <th>mov</th>\n",
       "      <th>p-d</th>\n",
       "      <th>pap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>humans</th>\n",
       "      <td>36 / 75</td>\n",
       "      <td>120 / 428</td>\n",
       "      <td>115 / 249</td>\n",
       "      <td>23 / 75</td>\n",
       "      <td>62 / 214</td>\n",
       "      <td>193 / 321</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>254 / 382</td>\n",
       "      <td>150 / 210</td>\n",
       "      <td>69 / 143</td>\n",
       "      <td>251 / 358</td>\n",
       "      <td>167 / 180</td>\n",
       "      <td>429 / 620</td>\n",
       "      <td>254 / 387</td>\n",
       "      <td>194 / 220</td>\n",
       "      <td>78 / 154</td>\n",
       "      <td>279 / 374</td>\n",
       "      <td>138 / 220</td>\n",
       "      <td>81 / 154</td>\n",
       "      <td>236 / 392</td>\n",
       "      <td>204 / 215</td>\n",
       "      <td>86 / 163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-1106</th>\n",
       "      <td>233 / 500</td>\n",
       "      <td>141 / 219</td>\n",
       "      <td>86 / 152</td>\n",
       "      <td>345 / 491</td>\n",
       "      <td>194 / 216</td>\n",
       "      <td>132 / 174</td>\n",
       "      <td>243 / 498</td>\n",
       "      <td>175 / 220</td>\n",
       "      <td>86 / 172</td>\n",
       "      <td>349 / 498</td>\n",
       "      <td>140 / 220</td>\n",
       "      <td>101 / 167</td>\n",
       "      <td>290 / 496</td>\n",
       "      <td>201 / 216</td>\n",
       "      <td>103 / 170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama-3.1-70b</th>\n",
       "      <td>269 / 500</td>\n",
       "      <td>122 / 220</td>\n",
       "      <td>104 / 166</td>\n",
       "      <td>368 / 500</td>\n",
       "      <td>169 / 220</td>\n",
       "      <td>152 / 183</td>\n",
       "      <td>277 / 500</td>\n",
       "      <td>141 / 220</td>\n",
       "      <td>104 / 186</td>\n",
       "      <td>354 / 500</td>\n",
       "      <td>130 / 220</td>\n",
       "      <td>117 / 186</td>\n",
       "      <td>329 / 496</td>\n",
       "      <td>164 / 219</td>\n",
       "      <td>121 / 185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixtral-8x22b</th>\n",
       "      <td>323 / 466</td>\n",
       "      <td>167 / 220</td>\n",
       "      <td>115 / 163</td>\n",
       "      <td>315 / 435</td>\n",
       "      <td>209 / 220</td>\n",
       "      <td>147 / 183</td>\n",
       "      <td>292 / 452</td>\n",
       "      <td>200 / 220</td>\n",
       "      <td>105 / 182</td>\n",
       "      <td>342 / 453</td>\n",
       "      <td>168 / 220</td>\n",
       "      <td>117 / 184</td>\n",
       "      <td>302 / 455</td>\n",
       "      <td>215 / 220</td>\n",
       "      <td>111 / 182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen2.5-72b</th>\n",
       "      <td>179 / 498</td>\n",
       "      <td>138 / 220</td>\n",
       "      <td>81 / 166</td>\n",
       "      <td>306 / 500</td>\n",
       "      <td>196 / 220</td>\n",
       "      <td>143 / 184</td>\n",
       "      <td>210 / 500</td>\n",
       "      <td>160 / 220</td>\n",
       "      <td>93 / 186</td>\n",
       "      <td>347 / 499</td>\n",
       "      <td>132 / 220</td>\n",
       "      <td>105 / 186</td>\n",
       "      <td>347 / 500</td>\n",
       "      <td>204 / 220</td>\n",
       "      <td>109 / 185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "desc_model         gpt-3.5-turbo                       gpt-4-1106             \\\n",
       "task                         mov        p-d        pap        mov        p-d   \n",
       "cmp_model                                                                      \n",
       "humans                   36 / 75  120 / 428  115 / 249    23 / 75   62 / 214   \n",
       "gpt-3.5-turbo          254 / 382  150 / 210   69 / 143  251 / 358  167 / 180   \n",
       "gpt-4-1106             233 / 500  141 / 219   86 / 152  345 / 491  194 / 216   \n",
       "meta-llama-3.1-70b     269 / 500  122 / 220  104 / 166  368 / 500  169 / 220   \n",
       "mixtral-8x22b          323 / 466  167 / 220  115 / 163  315 / 435  209 / 220   \n",
       "qwen2.5-72b            179 / 498  138 / 220   81 / 166  306 / 500  196 / 220   \n",
       "\n",
       "desc_model                    meta-llama-3.1-70b                        \\\n",
       "task                      pap                mov        p-d        pap   \n",
       "cmp_model                                                                \n",
       "humans              193 / 321                                            \n",
       "gpt-3.5-turbo       429 / 620          254 / 387  194 / 220   78 / 154   \n",
       "gpt-4-1106          132 / 174          243 / 498  175 / 220   86 / 172   \n",
       "meta-llama-3.1-70b  152 / 183          277 / 500  141 / 220  104 / 186   \n",
       "mixtral-8x22b       147 / 183          292 / 452  200 / 220  105 / 182   \n",
       "qwen2.5-72b         143 / 184          210 / 500  160 / 220   93 / 186   \n",
       "\n",
       "desc_model         mixtral-8x22b                       qwen2.5-72b             \\\n",
       "task                         mov        p-d        pap         mov        p-d   \n",
       "cmp_model                                                                       \n",
       "humans                                                                          \n",
       "gpt-3.5-turbo          279 / 374  138 / 220   81 / 154   236 / 392  204 / 215   \n",
       "gpt-4-1106             349 / 498  140 / 220  101 / 167   290 / 496  201 / 216   \n",
       "meta-llama-3.1-70b     354 / 500  130 / 220  117 / 186   329 / 496  164 / 219   \n",
       "mixtral-8x22b          342 / 453  168 / 220  117 / 184   302 / 455  215 / 220   \n",
       "qwen2.5-72b            347 / 499  132 / 220  105 / 186   347 / 500  204 / 220   \n",
       "\n",
       "desc_model                     \n",
       "task                      pap  \n",
       "cmp_model                      \n",
       "humans                         \n",
       "gpt-3.5-turbo        86 / 163  \n",
       "gpt-4-1106          103 / 170  \n",
       "meta-llama-3.1-70b  121 / 185  \n",
       "mixtral-8x22b       111 / 182  \n",
       "qwen2.5-72b         109 / 185  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a pivot table with cmp_model as rows and desc_model as columns\n",
    "# First create a helper column combining name and ftype for products\n",
    "\n",
    "df2_table = df2.copy()\n",
    "df2_table['task'] = df2_table.apply(lambda x: \n",
    "    \"mov\" if x['name'] == 'movie' \n",
    "    else \"pap\" if x['name'] == 'paper'\n",
    "    else 'p-d' if (x['name'] == 'product' and x['ftype'] == 'from_json_details')\n",
    "    # else 'p-pl' if (x['name'] == 'product' and x['ftype'] == 'from_json_product_listing')\n",
    "    else x['name'], axis=1)\n",
    "\n",
    "# Add formatted column combining value and p-value\n",
    "df2_table['formatted'] = df2_table.apply(lambda x: f\"{x['value']:.3f} ({x['p_value']:.3f})\", axis=1)\n",
    "df2_table['formatted2'] = df2_table.apply(lambda x: f\"{x['llm_count']} / {x['size']}\", axis=1)\n",
    "\n",
    "# Create pivot table\n",
    "pivot = pd.pivot_table(df2_table, \n",
    "                      values='formatted',\n",
    "                      index=['cmp_model'],\n",
    "                      columns=['desc_model', 'task'],\n",
    "                      aggfunc='sum',\n",
    "                      fill_value=\"\")\n",
    "# Sort pivot2 with custom key to put \"humans\" first\n",
    "pivot = pivot.reindex(sorted(pivot.index, key=lambda x: (\"\" if x == \"humans\" else x)))\n",
    "\n",
    "\n",
    "pivot2 = pd.pivot_table(df2_table,\n",
    "                      values='formatted2',\n",
    "                      index=['cmp_model'],\n",
    "                      columns=['desc_model', 'task'],\n",
    "                      aggfunc='sum',\n",
    "                      fill_value=\"\")\n",
    "# Sort pivot2 with custom key to put \"humans\" first\n",
    "pivot2 = pivot2.reindex(sorted(pivot2.index, key=lambda x: (\"\" if x == \"humans\" else x)))\n",
    "\n",
    "pd.set_option('display.max_rows', None, 'display.max_columns', None, 'display.precision', 3)\n",
    "\n",
    "print(\"\\nPivot table showing value and p-value for task counts:\")\n",
    "\n",
    "display(pivot)\n",
    "\n",
    "print(\"\\nPivot table showing absolute counts (preference-for-llm of total valid):\")\n",
    "\n",
    "display(pivot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72534668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\definecolor{value-above}{rgb}{0.7,0.1,0.1}\n",
      "\\definecolor{value-below}{rgb}{0.1,0.1,0.7}\n",
      "\\definecolor{value-neutral}{rgb}{0.3,0.3,0.3}\n",
      "\n",
      "\\begin{tabular}{lp{1.0cm}p{1.0cm}p{1.0cm}p{1.0cm}p{1.0cm}p{1.0cm}p{1.0cm}p{1.0cm}p{1.0cm}p{1.0cm}}\n",
      "\\hline\n",
      "\\textbf{Generator} & \\multicolumn{2}{c}{gpt-3.5-turbo} & \\multicolumn{2}{c}{gpt-4-1106} & \\multicolumn{2}{c}{llama-3.1-70b} & \\multicolumn{2}{c}{mixtral-8x22b} & \\multicolumn{2}{c}{qwen2.5-72b} \\\\\n",
      "\\textbf{Task} & {\\centering movie} & {\\centering paper} & {\\centering movie} & {\\centering paper} & {\\centering movie} & {\\centering paper} & {\\centering movie} & {\\centering paper} & {\\centering movie} & {\\centering paper} \\\\\n",
      "\\\\[-2ex]\\hline\\\\[-2ex]\n",
      "\n",
      "\\textbf{humans} & \\textcolor{value-neutral}{\\makecell[l]{0.480\\\\{\\footnotesize\\ \\ (0.818)}}} & \\textcolor{value-neutral}{\\makecell[l]{0.462\\\\{\\footnotesize\\ \\ (0.254)}}} & \\textcolor{value-below}{\\makecell[l]{0.307\\\\{\\footnotesize\\ \\ (0.001)}}} & \\textcolor{value-above}{\\makecell[l]{0.601\\\\{\\footnotesize\\ \\ (0.000)}}} &  &  &  &  &  &  \\\\\n",
      "\\textbf{gpt-3.5-turbo} & \\textcolor{value-above}{\\makecell[l]{0.665\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-neutral}{\\makecell[l]{0.483\\\\{\\footnotesize\\ \\ (0.738)}}} & \\textcolor{value-above}{\\makecell[l]{0.701\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.692\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.656\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-neutral}{\\makecell[l]{0.506\\\\{\\footnotesize\\ \\ (0.936)}}} & \\textcolor{value-above}{\\makecell[l]{0.746\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-neutral}{\\makecell[l]{0.526\\\\{\\footnotesize\\ \\ (0.573)}}} & \\textcolor{value-above}{\\makecell[l]{0.602\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-neutral}{\\makecell[l]{0.528\\\\{\\footnotesize\\ \\ (0.531)}}} \\\\\n",
      "\\textbf{gpt-4-1106} & \\textcolor{value-neutral}{\\makecell[l]{0.466\\\\{\\footnotesize\\ \\ (0.140)}}} & \\textcolor{value-neutral}{\\makecell[l]{0.566\\\\{\\footnotesize\\ \\ (0.123)}}} & \\textcolor{value-above}{\\makecell[l]{0.703\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.759\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-neutral}{\\makecell[l]{0.488\\\\{\\footnotesize\\ \\ (0.622)}}} & \\textcolor{value-neutral}{\\makecell[l]{0.500\\\\{\\footnotesize\\ \\ (1.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.701\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.605\\\\{\\footnotesize\\ \\ (0.008)}}} & \\textcolor{value-above}{\\makecell[l]{0.585\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.606\\\\{\\footnotesize\\ \\ (0.007)}}} \\\\\n",
      "\\textbf{llama-3.1-70b} & \\textcolor{value-neutral}{\\makecell[l]{0.538\\\\{\\footnotesize\\ \\ (0.098)}}} & \\textcolor{value-above}{\\makecell[l]{0.627\\\\{\\footnotesize\\ \\ (0.001)}}} & \\textcolor{value-above}{\\makecell[l]{0.736\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.831\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.554\\\\{\\footnotesize\\ \\ (0.018)}}} & \\textcolor{value-neutral}{\\makecell[l]{0.559\\\\{\\footnotesize\\ \\ (0.123)}}} & \\textcolor{value-above}{\\makecell[l]{0.708\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.629\\\\{\\footnotesize\\ \\ (0.001)}}} & \\textcolor{value-above}{\\makecell[l]{0.663\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.654\\\\{\\footnotesize\\ \\ (0.000)}}} \\\\\n",
      "\\textbf{mixtral-8x22b} & \\textcolor{value-above}{\\makecell[l]{0.693\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.706\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.724\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.803\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.646\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.577\\\\{\\footnotesize\\ \\ (0.045)}}} & \\textcolor{value-above}{\\makecell[l]{0.755\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.636\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.664\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.610\\\\{\\footnotesize\\ \\ (0.004)}}} \\\\\n",
      "\\textbf{qwen2.5-72b} & \\textcolor{value-below}{\\makecell[l]{0.359\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-neutral}{\\makecell[l]{0.488\\\\{\\footnotesize\\ \\ (0.816)}}} & \\textcolor{value-above}{\\makecell[l]{0.612\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.777\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-below}{\\makecell[l]{0.420\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-neutral}{\\makecell[l]{0.500\\\\{\\footnotesize\\ \\ (1.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.695\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-neutral}{\\makecell[l]{0.565\\\\{\\footnotesize\\ \\ (0.091)}}} & \\textcolor{value-above}{\\makecell[l]{0.694\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.589\\\\{\\footnotesize\\ \\ (0.018)}}} \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\\begin{tabular}{lp{1.0cm}p{1.0cm}p{1.0cm}p{1.0cm}p{1.0cm}}\n",
      "\\hline\n",
      "\\textbf{Generator} \\\\[0.5em] & gpt-3.5-turbo \\\\[0.5em] & gpt-4-1106 \\\\[0.5em] & llama-3.1-70b \\\\[0.5em] & mixtral-8x22b \\\\[0.5em] & qwen2.5-72b \\\\\n",
      "\\textbf{Task} & {\\centering prod. details} & {\\centering prod. details} & {\\centering prod. details} & {\\centering prod. details} & {\\centering prod. details} \\\\\n",
      "\\\\[-2ex]\\hline\\\\[-2ex]\n",
      "\n",
      "\\textbf{humans} & \\textcolor{value-below}{\\makecell[l]{0.280\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-below}{\\makecell[l]{0.290\\\\{\\footnotesize\\ \\ (0.000)}}} &  &  &  \\\\\n",
      "\\textbf{gpt-3.5-turbo} & \\textcolor{value-above}{\\makecell[l]{0.714\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.928\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.882\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.627\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.949\\\\{\\footnotesize\\ \\ (0.000)}}} \\\\\n",
      "\\textbf{gpt-4-1106} & \\textcolor{value-above}{\\makecell[l]{0.644\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.898\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.795\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.636\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.931\\\\{\\footnotesize\\ \\ (0.000)}}} \\\\\n",
      "\\textbf{llama-3.1-70b} & \\textcolor{value-neutral}{\\makecell[l]{0.555\\\\{\\footnotesize\\ \\ (0.121)}}} & \\textcolor{value-above}{\\makecell[l]{0.768\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.641\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.591\\\\{\\footnotesize\\ \\ (0.008)}}} & \\textcolor{value-above}{\\makecell[l]{0.749\\\\{\\footnotesize\\ \\ (0.000)}}} \\\\\n",
      "\\textbf{mixtral-8x22b} & \\textcolor{value-above}{\\makecell[l]{0.759\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.950\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.909\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.764\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.977\\\\{\\footnotesize\\ \\ (0.000)}}} \\\\\n",
      "\\textbf{qwen2.5-72b} & \\textcolor{value-above}{\\makecell[l]{0.627\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.891\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.727\\\\{\\footnotesize\\ \\ (0.000)}}} & \\textcolor{value-above}{\\makecell[l]{0.600\\\\{\\footnotesize\\ \\ (0.004)}}} & \\textcolor{value-above}{\\makecell[l]{0.927\\\\{\\footnotesize\\ \\ (0.000)}}} \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Format the pivot table data for LaTeX\n",
    "def create_latex_table(\n",
    "    df2_table,\n",
    "    tasks=None,\n",
    "    desc_models=None,\n",
    "    cmp_models=None,\n",
    "    with_common_defs=True,\n",
    "    short_task_names=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a LaTeX table from the data with customizable filtering and formatting options.\n",
    "\n",
    "    Args:\n",
    "        df2_table: DataFrame with the source data\n",
    "        tasks: List of task names to include (None = all)\n",
    "        desc_models: List of description models to include (None = all)\n",
    "        cmp_models: List of comparison models to include (None = all)\n",
    "        with_common_defs: Whether to include color definitions\n",
    "        short_task_names: Whether to use shortened task names\n",
    "    \"\"\"\n",
    "    # Filter data if needed\n",
    "    data = df2_table.copy()\n",
    "    if tasks is not None:\n",
    "        data = data[data[\"task\"].isin(tasks)]\n",
    "    if desc_models is not None:\n",
    "        data = data[data[\"desc_model\"].isin(desc_models)]\n",
    "    if cmp_models is not None:\n",
    "        data = data[data[\"cmp_model\"].isin(cmp_models)]\n",
    "\n",
    "    # Format items\n",
    "    def fmt_item(value, p_value):\n",
    "        if p_value >= 0.05:\n",
    "            color = \"\\\\textcolor{value-neutral}{\"\n",
    "            end_color = \"}\"\n",
    "        elif value > 0.5:\n",
    "            color = \"\\\\textcolor{value-above}{\"\n",
    "            end_color = \"}\"\n",
    "        else:\n",
    "            color = \"\\\\textcolor{value-below}{\"\n",
    "            end_color = \"}\"\n",
    "        return f\"{color}\\\\makecell[l]{{{value:.3f}\\\\\\\\{{\\\\footnotesize\\\\ \\\\ ({p_value:.3f})}}}}{end_color}\"\n",
    "\n",
    "    data[\"formatted\"] = data.apply(lambda x: fmt_item(x[\"value\"], x[\"p_value\"]), axis=1)\n",
    "\n",
    "    # Create pivot table\n",
    "    latex_pivot = pd.pivot_table(\n",
    "        data,\n",
    "        values=\"formatted\",\n",
    "        index=[\"cmp_model\"],\n",
    "        columns=[\"desc_model\", \"task\"],\n",
    "        aggfunc=\"sum\",\n",
    "        fill_value=\"\",\n",
    "    )\n",
    "    # Sort pivot2 with custom key to put \"humans\" first\n",
    "    latex_pivot = latex_pivot.reindex(sorted(latex_pivot.index, key=lambda x: (\"\" if x == \"humans\" else x)))\n",
    "\n",
    "\n",
    "    # Start building LaTeX string\n",
    "    latex_str = \"\"\n",
    "    if with_common_defs:\n",
    "        latex_str = \"\"\"\n",
    "\\\\definecolor{value-above}{rgb}{0.7,0.1,0.1}\n",
    "\\\\definecolor{value-below}{rgb}{0.1,0.1,0.7}\n",
    "\\\\definecolor{value-neutral}{rgb}{0.3,0.3,0.3}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    # Convert to LaTeX\n",
    "    latex_str += latex_pivot.to_latex(\n",
    "        column_format=\"l\" + \"p{1.0cm}\" * len(latex_pivot.columns),\n",
    "        multicolumn=True,\n",
    "        multicolumn_format=\"c\",\n",
    "        header=True,\n",
    "        bold_rows=True,\n",
    "    )\n",
    "\n",
    "    # Clean up LaTeX output\n",
    "    latex_str = latex_str.replace(\"\\\\toprule\", \"\\\\hline\")\n",
    "    latex_str = latex_str.replace(\"\\\\midrule\", \"\")\n",
    "    latex_str = latex_str.replace(\"\\\\bottomrule\", \"\\\\hline\")\n",
    "\n",
    "    # Handle task names\n",
    "    if short_task_names:\n",
    "        replacements = {\n",
    "            \"mov\": \"{\\\\centering mov}\",\n",
    "            \"p-d\": \"{\\\\centering p-d}\",\n",
    "            \"p-pl\": \"{\\\\centering p-pl}\",\n",
    "            \"pap\": \"{\\\\centering pap}\",\n",
    "        }\n",
    "    else:\n",
    "        replacements = {\n",
    "            \"mov\": \"{\\\\centering movie}\",\n",
    "            \"p-d\": \"{\\\\centering prod. details}\",\n",
    "            \"p-pl\": \"{\\\\centering prod. listing}\",\n",
    "            \"pap\": \"{\\\\centering paper}\",\n",
    "        }\n",
    "\n",
    "    for old, new in replacements.items():\n",
    "        latex_str = latex_str.replace(old, new)\n",
    "\n",
    "    # Add spacing between model groups\n",
    "    model_groups = [\"gpt-3.5-turbo\", \"gpt-4-1106\", \"meta-llama\", \"mixtral\", \"qwen\"]\n",
    "    for model in model_groups:\n",
    "        latex_str = latex_str.replace(f\"& {model}\", f\"\\\\\\\\[0.5em] & {model}\")\n",
    "    latex_str = latex_str.replace(\"meta-\", \"\")\n",
    "\n",
    "    # Replace headers\n",
    "    latex_str = latex_str.replace(\"desc_model\", \"\\\\textbf{Generator}\")\n",
    "    latex_str = latex_str.replace(\"task\", \"\\\\textbf{Task}\")\n",
    "    latex_str = re.sub(r\"cmp_model.*\", r\"\\\\\\\\[-2ex]\\\\hline\\\\\\\\[-2ex]\", latex_str)\n",
    "    return latex_str\n",
    "\n",
    "print(create_latex_table(df2_table, tasks=[\"mov\", \"pap\"], short_task_names=False))\n",
    "print()\n",
    "print(create_latex_table(df2_table, tasks=[\"p-d\", \"p-pl\"], with_common_defs=False, short_task_names=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7704c869-3a2b-4d33-958f-f25334e83943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = df2.groupby([\"name\", \"ftype\", \"desc_model\", \"cmp_model\"]).size()\n",
    "s[s > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "016cdc7e-8d1c-4a1c-aeaf-a991931d2fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_model</th>\n",
       "      <th>cmp_model</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>movie</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>paper</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>product/details</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>movie</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>paper</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>product/details</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>humans</td>\n",
       "      <td>movie</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>humans</td>\n",
       "      <td>paper</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>humans</td>\n",
       "      <td>product/details</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>movie</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>paper</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>product/details</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>movie</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>paper</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>product/details</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>movie</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>paper</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>product/details</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>movie</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>paper</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>product/details</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>movie</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>paper</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>product/details</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>humans</td>\n",
       "      <td>movie</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>humans</td>\n",
       "      <td>paper</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>humans</td>\n",
       "      <td>product/details</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>movie</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>paper</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>product/details</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>movie</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>paper</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>product/details</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>movie</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>paper</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>product/details</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>movie</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>paper</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>product/details</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>movie</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>paper</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>product/details</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>movie</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>paper</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>product/details</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>movie</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>paper</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>product/details</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>movie</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>paper</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>product/details</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>movie</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>paper</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>product/details</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>movie</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>paper</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>product/details</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>movie</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>paper</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>product/details</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>movie</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>paper</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>product/details</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>movie</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>paper</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>product/details</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>movie</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>paper</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>product/details</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>movie</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>paper</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>gpt-4-1106</td>\n",
       "      <td>product/details</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>movie</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>paper</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>meta-llama-3.1-70b</td>\n",
       "      <td>product/details</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>movie</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>paper</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>mixtral-8x22b</td>\n",
       "      <td>product/details</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>movie</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>paper</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>qwen2.5-72b</td>\n",
       "      <td>product/details</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            desc_model           cmp_model            title  size\n",
       "0        gpt-3.5-turbo       gpt-3.5-turbo            movie   382\n",
       "1        gpt-3.5-turbo       gpt-3.5-turbo            paper   143\n",
       "2        gpt-3.5-turbo       gpt-3.5-turbo  product/details   210\n",
       "3        gpt-3.5-turbo          gpt-4-1106            movie   500\n",
       "4        gpt-3.5-turbo          gpt-4-1106            paper   152\n",
       "5        gpt-3.5-turbo          gpt-4-1106  product/details   219\n",
       "6        gpt-3.5-turbo              humans            movie    75\n",
       "7        gpt-3.5-turbo              humans            paper   249\n",
       "8        gpt-3.5-turbo              humans  product/details   428\n",
       "9        gpt-3.5-turbo  meta-llama-3.1-70b            movie   500\n",
       "10       gpt-3.5-turbo  meta-llama-3.1-70b            paper   166\n",
       "11       gpt-3.5-turbo  meta-llama-3.1-70b  product/details   220\n",
       "12       gpt-3.5-turbo       mixtral-8x22b            movie   466\n",
       "13       gpt-3.5-turbo       mixtral-8x22b            paper   163\n",
       "14       gpt-3.5-turbo       mixtral-8x22b  product/details   220\n",
       "15       gpt-3.5-turbo         qwen2.5-72b            movie   498\n",
       "16       gpt-3.5-turbo         qwen2.5-72b            paper   166\n",
       "17       gpt-3.5-turbo         qwen2.5-72b  product/details   220\n",
       "18          gpt-4-1106       gpt-3.5-turbo            movie   358\n",
       "19          gpt-4-1106       gpt-3.5-turbo            paper   620\n",
       "20          gpt-4-1106       gpt-3.5-turbo  product/details   180\n",
       "21          gpt-4-1106          gpt-4-1106            movie   491\n",
       "22          gpt-4-1106          gpt-4-1106            paper   174\n",
       "23          gpt-4-1106          gpt-4-1106  product/details   216\n",
       "24          gpt-4-1106              humans            movie    75\n",
       "25          gpt-4-1106              humans            paper   321\n",
       "26          gpt-4-1106              humans  product/details   214\n",
       "27          gpt-4-1106  meta-llama-3.1-70b            movie   500\n",
       "28          gpt-4-1106  meta-llama-3.1-70b            paper   183\n",
       "29          gpt-4-1106  meta-llama-3.1-70b  product/details   220\n",
       "30          gpt-4-1106       mixtral-8x22b            movie   435\n",
       "31          gpt-4-1106       mixtral-8x22b            paper   183\n",
       "32          gpt-4-1106       mixtral-8x22b  product/details   220\n",
       "33          gpt-4-1106         qwen2.5-72b            movie   500\n",
       "34          gpt-4-1106         qwen2.5-72b            paper   184\n",
       "35          gpt-4-1106         qwen2.5-72b  product/details   220\n",
       "36  meta-llama-3.1-70b       gpt-3.5-turbo            movie   387\n",
       "37  meta-llama-3.1-70b       gpt-3.5-turbo            paper   154\n",
       "38  meta-llama-3.1-70b       gpt-3.5-turbo  product/details   220\n",
       "39  meta-llama-3.1-70b          gpt-4-1106            movie   498\n",
       "40  meta-llama-3.1-70b          gpt-4-1106            paper   172\n",
       "41  meta-llama-3.1-70b          gpt-4-1106  product/details   220\n",
       "42  meta-llama-3.1-70b  meta-llama-3.1-70b            movie   500\n",
       "43  meta-llama-3.1-70b  meta-llama-3.1-70b            paper   186\n",
       "44  meta-llama-3.1-70b  meta-llama-3.1-70b  product/details   220\n",
       "45  meta-llama-3.1-70b       mixtral-8x22b            movie   452\n",
       "46  meta-llama-3.1-70b       mixtral-8x22b            paper   182\n",
       "47  meta-llama-3.1-70b       mixtral-8x22b  product/details   220\n",
       "48  meta-llama-3.1-70b         qwen2.5-72b            movie   500\n",
       "49  meta-llama-3.1-70b         qwen2.5-72b            paper   186\n",
       "50  meta-llama-3.1-70b         qwen2.5-72b  product/details   220\n",
       "51       mixtral-8x22b       gpt-3.5-turbo            movie   374\n",
       "52       mixtral-8x22b       gpt-3.5-turbo            paper   154\n",
       "53       mixtral-8x22b       gpt-3.5-turbo  product/details   220\n",
       "54       mixtral-8x22b          gpt-4-1106            movie   498\n",
       "55       mixtral-8x22b          gpt-4-1106            paper   167\n",
       "56       mixtral-8x22b          gpt-4-1106  product/details   220\n",
       "57       mixtral-8x22b  meta-llama-3.1-70b            movie   500\n",
       "58       mixtral-8x22b  meta-llama-3.1-70b            paper   186\n",
       "59       mixtral-8x22b  meta-llama-3.1-70b  product/details   220\n",
       "60       mixtral-8x22b       mixtral-8x22b            movie   453\n",
       "61       mixtral-8x22b       mixtral-8x22b            paper   184\n",
       "62       mixtral-8x22b       mixtral-8x22b  product/details   220\n",
       "63       mixtral-8x22b         qwen2.5-72b            movie   499\n",
       "64       mixtral-8x22b         qwen2.5-72b            paper   186\n",
       "65       mixtral-8x22b         qwen2.5-72b  product/details   220\n",
       "66         qwen2.5-72b       gpt-3.5-turbo            movie   392\n",
       "67         qwen2.5-72b       gpt-3.5-turbo            paper   163\n",
       "68         qwen2.5-72b       gpt-3.5-turbo  product/details   215\n",
       "69         qwen2.5-72b          gpt-4-1106            movie   496\n",
       "70         qwen2.5-72b          gpt-4-1106            paper   170\n",
       "71         qwen2.5-72b          gpt-4-1106  product/details   216\n",
       "72         qwen2.5-72b  meta-llama-3.1-70b            movie   496\n",
       "73         qwen2.5-72b  meta-llama-3.1-70b            paper   185\n",
       "74         qwen2.5-72b  meta-llama-3.1-70b  product/details   219\n",
       "75         qwen2.5-72b       mixtral-8x22b            movie   455\n",
       "76         qwen2.5-72b       mixtral-8x22b            paper   182\n",
       "77         qwen2.5-72b       mixtral-8x22b  product/details   220\n",
       "78         qwen2.5-72b         qwen2.5-72b            movie   500\n",
       "79         qwen2.5-72b         qwen2.5-72b            paper   185\n",
       "80         qwen2.5-72b         qwen2.5-72b  product/details   220"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = df2.groupby([\"desc_model\", \"cmp_model\", \"title\"], as_index=False)[\"size\"].sum()\n",
    "d\n",
    "\n",
    "d = d[~d.title.str.contains(\"listing\")]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b93d9933-7780-4a44-8dd4-d4dd9340500e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie / from_title_and_year\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "cmp_model: %{x}<br>desc_model: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z:.2f}",
         "type": "heatmap",
         "x": [
          "humans",
          "gpt-3.5-turbo",
          "gpt-4-1106",
          "meta-llama-3.1-70b",
          "mixtral-8x22b",
          "qwen2.5-72b"
         ],
         "xaxis": "x",
         "y": [
          "gpt-3.5-turbo",
          "gpt-4-1106",
          "meta-llama-3.1-70b",
          "mixtral-8x22b",
          "qwen2.5-72b"
         ],
         "yaxis": "y",
         "z": [
          [
           0.48,
           0.6649214659685864,
           0.466,
           0.538,
           0.6931330472103004,
           0.35943775100401604
          ],
          [
           0.30666666666666664,
           0.7011173184357542,
           0.7026476578411406,
           0.736,
           0.7241379310344828,
           0.612
          ],
          [
           null,
           0.6563307493540051,
           0.4879518072289157,
           0.554,
           0.6460176991150443,
           0.42
          ],
          [
           null,
           0.7459893048128342,
           0.7008032128514057,
           0.708,
           0.7549668874172185,
           0.6953907815631263
          ],
          [
           null,
           0.6020408163265306,
           0.5846774193548387,
           0.6633064516129032,
           0.6637362637362637,
           0.694
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "cmid": 0.5,
         "colorscale": [
          [
           0,
           "rgb(5,48,97)"
          ],
          [
           0.1,
           "rgb(33,102,172)"
          ],
          [
           0.2,
           "rgb(67,147,195)"
          ],
          [
           0.3,
           "rgb(146,197,222)"
          ],
          [
           0.4,
           "rgb(209,229,240)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(253,219,199)"
          ],
          [
           0.7,
           "rgb(244,165,130)"
          ],
          [
           0.8,
           "rgb(214,96,77)"
          ],
          [
           0.9,
           "rgb(178,24,43)"
          ],
          [
           1,
           "rgb(103,0,31)"
          ]
         ]
        },
        "height": 700,
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "rgba(0, 0, 0, 0)",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Heatmap for movie / from_title_and_year"
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "cmp_model"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "desc_model"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"fd9527c5-4998-4142-93ea-d9fdae72c320\" class=\"plotly-graph-div\" style=\"height:700px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fd9527c5-4998-4142-93ea-d9fdae72c320\")) {                    Plotly.newPlot(                        \"fd9527c5-4998-4142-93ea-d9fdae72c320\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"texttemplate\":\"%{z:.2f}\",\"x\":[\"humans\",\"gpt-3.5-turbo\",\"gpt-4-1106\",\"meta-llama-3.1-70b\",\"mixtral-8x22b\",\"qwen2.5-72b\"],\"y\":[\"gpt-3.5-turbo\",\"gpt-4-1106\",\"meta-llama-3.1-70b\",\"mixtral-8x22b\",\"qwen2.5-72b\"],\"z\":[[0.48,0.6649214659685864,0.466,0.538,0.6931330472103004,0.35943775100401604],[0.30666666666666664,0.7011173184357542,0.7026476578411406,0.736,0.7241379310344828,0.612],[null,0.6563307493540051,0.4879518072289157,0.554,0.6460176991150443,0.42],[null,0.7459893048128342,0.7008032128514057,0.708,0.7549668874172185,0.6953907815631263],[null,0.6020408163265306,0.5846774193548387,0.6633064516129032,0.6637362637362637,0.694]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"cmp_model: %{x}\\u003cbr\\u003edesc_model: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"cmp_model\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"desc_model\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(5,48,97)\"],[0.1,\"rgb(33,102,172)\"],[0.2,\"rgb(67,147,195)\"],[0.3,\"rgb(146,197,222)\"],[0.4,\"rgb(209,229,240)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(253,219,199)\"],[0.7,\"rgb(244,165,130)\"],[0.8,\"rgb(214,96,77)\"],[0.9,\"rgb(178,24,43)\"],[1.0,\"rgb(103,0,31)\"]],\"cmid\":0.5},\"margin\":{\"t\":60},\"height\":700,\"plot_bgcolor\":\"rgba(0, 0, 0, 0)\",\"title\":{\"text\":\"Heatmap for movie \\u002f from_title_and_year\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('fd9527c5-4998-4142-93ea-d9fdae72c320');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/movie_from_title_and_year_heatmap.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# save as pdf\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mftype\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_heatmap.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/wombat_share/laurito/ai-ai-bias/.venv/lib/python3.10/site-packages/plotly/basedatatypes.py:3835\u001b[0m, in \u001b[0;36mBaseFigure.write_image\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3775\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3776\u001b[0m \u001b[38;5;124;03mConvert a figure to a static image and write it to a file or writeable\u001b[39;00m\n\u001b[1;32m   3777\u001b[0m \u001b[38;5;124;03mobject\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3831\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[1;32m   3832\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3833\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[0;32m-> 3835\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/wombat_share/laurito/ai-ai-bias/.venv/lib/python3.10/site-packages/plotly/io/_kaleido.py:296\u001b[0m, in \u001b[0;36mwrite_image\u001b[0;34m(fig, file, format, scale, width, height, validate, engine)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    287\u001b[0m \u001b[38;5;250m            \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03mThe 'file' argument '{file}' is not a string, pathlib.Path object, or file descriptor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m             )\n\u001b[1;32m    292\u001b[0m         )\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;66;03m# We previously succeeded in interpreting `file` as a pathlib object.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;66;03m# Now we can use `write_bytes()`.\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m         \u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/pathlib.py:1143\u001b[0m, in \u001b[0;36mPath.write_bytes\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;66;03m# type-check for the buffer interface before truncating the file\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m view \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(data)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mwrite(view)\n",
      "File \u001b[0;32m/usr/lib/python3.10/pathlib.py:1119\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1118\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m-> 1119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/movie_from_title_and_year_heatmap.pdf'"
     ]
    }
   ],
   "source": [
    "for name, ftype in list(df[[\"name\", \"ftype\"]].value_counts().index):\n",
    "    print(name, \"/\", ftype)\n",
    "    d = df2[(df2.ftype == ftype) & (df2.name == name)]\n",
    "    d = d.groupby([\"desc_model\", \"cmp_model\"], as_index=False).agg({\"value\": \"mean\"})\n",
    "\n",
    "    # Create pivot table\n",
    "    tab = d.pivot(index=\"desc_model\", columns=\"cmp_model\", values=\"value\")\n",
    "\n",
    "    # Reorder columns to move 'humans' to the left\n",
    "    if \"humans\" in tab.columns:\n",
    "        columns = [\"humans\"] + [col for col in tab.columns if col != \"humans\"]\n",
    "        tab = tab[columns]\n",
    "\n",
    "    # Generate heatmap\n",
    "    fig = px.imshow(\n",
    "        tab,\n",
    "        text_auto=\".2f\",\n",
    "        color_continuous_scale=\"RdBu_r\",\n",
    "        height=700,\n",
    "        color_continuous_midpoint=0.5,\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor=\"rgba(0, 0, 0, 0)\", title=f\"Heatmap for {name} / {ftype}\"\n",
    "    )\n",
    "    fig.show()\n",
    "    # save as pdf\n",
    "    fig.write_image(f\"visualizations/{name}_{ftype}_heatmap.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd97221-4fc5-4f3b-95ce-cfa4ec53ca34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8de420b-6b22-4a72-b9e1-b75a3d53f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2[(df2.name == \"product\") & (df2.ftype == \"from_json_details\")]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d218bdc-4d80-4780-86d9-9f3383e2684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure df2 is not None and has the required column\n",
    "if df2 is None:\n",
    "    raise ValueError(\"df2 is None. Make sure it's properly defined.\")\n",
    "\n",
    "if \"title\" not in df2.columns:\n",
    "    raise ValueError(\"Column 'title' is missing from df2.\")\n",
    "\n",
    "df = df2.copy()\n",
    "\n",
    "# Ensure title column has valid data\n",
    "if df[\"title\"].isnull().all():\n",
    "    raise ValueError(\"All values in 'title' column are NaN. Check the dataset.\")\n",
    "\n",
    "etype_order = {etype: i for i, etype in enumerate(df[\"title\"].unique())}\n",
    "\n",
    "# Ensure etype_order is not empty\n",
    "if not etype_order:\n",
    "    raise ValueError(\"etype_order is empty. The 'title' column may have no valid data.\")\n",
    "\n",
    "df[\"title_numeric\"] = df[\"title\"].map(etype_order)\n",
    "df[\"xindex\"] = df[\"title_numeric\"] + df[\"offset\"]\n",
    "\n",
    "# Sort values for better plotting\n",
    "df.sort_values(\"cmp_model\", inplace=True)\n",
    "\n",
    "# Define symbol map\n",
    "syms = [\"circle\", \"square\", \"diamond\", \"x\", \"triangle-left\", \"triangle-up\", \"triangle-down\", \"star\", \"pentagon\"]\n",
    "symbol_map = {name: s for name, s in zip(OFFSET_NAMES, syms)}\n",
    "\n",
    "# Create scatter plot\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    y=\"value\",\n",
    "    x=\"xindex\",\n",
    "    error_y=\"ci1\",\n",
    "    error_y_minus=\"ci0\",\n",
    "    symbol=\"cmp_model\",\n",
    "    color=\"cmp_model\",\n",
    "    facet_col=\"desc_model\",\n",
    "    facet_col_wrap=2,\n",
    "    width=1400,\n",
    "    height=600,  # Adjust height for two subplots\n",
    "    labels={\"xindex\": \"Dataset & Prompts\", \"gen_name\": \"Generator\"},\n",
    "    symbol_map=symbol_map,\n",
    ")\n",
    "\n",
    "# Ensure trace filtering does not fail\n",
    "filtered_traces = []\n",
    "for trace in fig.data:\n",
    "    if hasattr(trace, \"meta\") and isinstance(trace.meta, dict) and \"facet_row\" in trace.meta:\n",
    "        if trace.meta[\"facet_row\"] < 2:\n",
    "            filtered_traces.append(trace)\n",
    "\n",
    "fig.data = filtered_traces\n",
    "\n",
    "# Update trace markers and axes\n",
    "fig.update_traces(marker=dict(size=10))\n",
    "fig.update_yaxes(range=[0, 1], dtick=0.25)\n",
    "fig.update_xaxes(\n",
    "    tickvals=list(etype_order.values()),\n",
    "    ticktext=list(etype_order.keys())\n",
    ")\n",
    "\n",
    "# Add horizontal lines\n",
    "fig.add_hline(0.5, line_width=0.5)\n",
    "fig.add_hline(1, line_width=1)\n",
    "fig.add_hline(0.25, line_width=0.5, line_dash=\"10px 10px\")\n",
    "fig.add_hline(0.75, line_width=0.5, line_dash=\"10px 10px\")\n",
    "\n",
    "# Update axes and layout\n",
    "fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=False)\n",
    "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=False)\n",
    "\n",
    "# Clean facet annotations\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.replace(\"=\", \" \")))\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb547c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ci(value, size):\n",
    "    alpha = value * size\n",
    "    beta_ = (1 - value) * size\n",
    "    a, b = scipy.stats.beta.interval(0.95, alpha, beta_)\n",
    "    return value - a, b - value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e588710b-2946-47c1-bd22-02ccd6ed3d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2.copy()\n",
    "df[\"cmp_model\"] = df.cmp_model.apply(lambda x: \"Humans\" if x == \"Humans\" else \"LLM\")\n",
    "def f1(x):\n",
    "    return (x[\"value\"] * x[\"size\"]).sum() / x[\"size\"].sum()\n",
    "g = df.groupby([\"desc_model\", \"cmp_model\", \"title\"])\n",
    "df = pd.DataFrame({\"value\": g.apply(f1, include_groups=False), \"size\": g[\"size\"].sum()}).reset_index()\n",
    "df[[\"ci0\", \"ci1\"]] = df2.apply(lambda x: compute_ci(x[\"value\"], x[\"size\"]), axis=1, result_type='expand')\n",
    "df[\"offset\"] = df.cmp_model.apply(lambda x: -0.1 if x == \"Humans\" else 0)\n",
    "df.sort_values(\"cmp_model\")\n",
    "etype_order = {etype: i for i, etype in sorted(enumerate(df[\"title\"].unique()))}\n",
    "df[\"title_numeric\"] = df[\"title\"].map(etype_order)\n",
    "df[\"xindex\"] = df[\"title_numeric\"] + df[\"offset\"]\n",
    "syms = [\"circle\", \"square\", \"diamond\", \"x\", \"triangle-left\", \"triangle-up\", \"triangle-down\", \"star\", \"pentagon\"]\n",
    "symbol_map = { name: s for name, s in zip(OFFSET_NAMES, syms) }\n",
    "fig = px.scatter(df, y=\"value\", x=\"xindex\", error_y=\"ci1\", error_y_minus=\"ci0\", symbol=\"cmp_model\", color=\"cmp_model\", facet_col=\"desc_model\", width=1400, height=400, labels={\"xindex\": \"Dataset & Prompts\", \"gen_name\": \"Generator\"}, symbol_map=symbol_map)\n",
    "data = list(fig.data)\n",
    "data.sort(key=lambda x: x.name)\n",
    "fig.data = tuple(data)\n",
    "fig.data\n",
    "fig.update_traces(marker=dict(size=10))\n",
    "fig.update_yaxes(range=[0, 1], dtick = 0.25)\n",
    "fig.update_layout(\n",
    "    plot_bgcolor=\"rgba(0, 0, 0, 0)\",\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    tickvals=list(etype_order.values()),\n",
    "    ticktext=list(etype_order.keys()))\n",
    "fig.add_hline(0.5, line_width=0.5)\n",
    "fig.add_hline(1, line_width=1)\n",
    "fig.add_hline(0.25, line_width=0.5, line_dash=\"10px 10px\")\n",
    "fig.add_hline(0.75, line_width=0.5, line_dash=\"10px 10px\")\n",
    "\n",
    "fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=False)\n",
    "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=False)\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.replace(\"=\", \" \")))\n",
    "#fig.update_layout(legend={\"xanchor\": \"center\", \"x\": 0.5, \"y\": 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd259b-875f-4fd3-b9f3-c2ce47ae79e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2.copy()\n",
    "df[\"cmp_model\"] = df.cmp_model.apply(lambda x: \"Humans\" if x == \"Humans\" else \"LLM\")\n",
    "def f1(x):\n",
    "    return (x[\"value\"] * x[\"size\"]).sum() / x[\"size\"].sum()\n",
    "g = df.groupby([\"cmp_model\", \"title\"])\n",
    "df = pd.DataFrame({\"value\": g.apply(f1, include_groups=False), \"size\": g[\"size\"].sum()}).reset_index()\n",
    "df[[\"ci0\", \"ci1\"]] = df2.apply(lambda x: compute_ci(x[\"value\"], x[\"size\"]), axis=1, result_type='expand')\n",
    "df[\"offset\"] = df.cmp_model.apply(lambda x: -0.1 if x == \"Humans\" else 0)\n",
    "df.sort_values(\"cmp_model\")\n",
    "etype_order = {etype: i for i, etype in sorted(enumerate(df[\"title\"].unique()))}\n",
    "df[\"title_numeric\"] = df[\"title\"].map(etype_order)\n",
    "df[\"xindex\"] = df[\"title_numeric\"] + df[\"offset\"]\n",
    "syms = [\"circle\", \"square\", \"diamond\", \"x\", \"triangle-left\", \"triangle-up\", \"triangle-down\", \"star\", \"pentagon\"]\n",
    "symbol_map = { name: s for name, s in zip(OFFSET_NAMES, syms) }\n",
    "fig = px.scatter(df, y=\"value\", x=\"xindex\", error_y=\"ci1\", error_y_minus=\"ci0\", symbol=\"cmp_model\", color=\"cmp_model\", width=500, height=400, labels={\"xindex\": \"Dataset & Prompts\", \"gen_name\": \"Generator\"}, symbol_map=symbol_map)\n",
    "data = list(fig.data)\n",
    "data.sort(key=lambda x: x.name)\n",
    "fig.data = tuple(data)\n",
    "fig.data\n",
    "fig.update_traces(marker=dict(size=10))\n",
    "fig.update_yaxes(range=[0, 1], dtick = 0.25)\n",
    "fig.update_layout(\n",
    "    plot_bgcolor=\"rgba(0, 0, 0, 0)\",\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    tickvals=list(etype_order.values()),\n",
    "    ticktext=list(etype_order.keys()))\n",
    "fig.add_hline(0.5, line_width=0.5)\n",
    "fig.add_hline(1, line_width=1)\n",
    "fig.add_hline(0.25, line_width=0.5, line_dash=\"10px 10px\")\n",
    "fig.add_hline(0.75, line_width=0.5, line_dash=\"10px 10px\")\n",
    "\n",
    "fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=False)\n",
    "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=False)\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.replace(\"=\", \" \")))\n",
    "#fig.update_layout(legend={\"xanchor\": \"center\", \"x\": 0.5, \"y\": 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bd4690-62cd-47d8-9d11-f076d44b3976",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf41c4a-9f68-4e76-b88e-2f17d9dc08ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
